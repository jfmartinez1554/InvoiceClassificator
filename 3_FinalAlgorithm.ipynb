{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd3548de",
   "metadata": {},
   "source": [
    "# Algoritmo final de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f2fc3f",
   "metadata": {},
   "source": [
    "En este notebook pondremos a prueba el algoritmo, simulando la entrada de nuevos registros para su clasificación, haciendo la salvedad de que los nuevos registros provienen de tiendas no incluidas en el dataset de entrenamiento ni validación de los modelos. Lo anterior con el fin de asegurarnos de que los modelos no padezcan de sobreajuste.\n",
    "\n",
    "Así mismo, formularemos el algoritmo completo de clasificación que servirá de entregable final para la formulación de un prototipo dentro del área de analítica de Bancolombia. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08d0e9e",
   "metadata": {},
   "source": [
    "Iniciaremos con la configuración del ambiente de ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcf1e5a8-559d-4732-a2bb-5d399fffd537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads Constants, imports and utilitary functions\n",
    "%run 0_Utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fad076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install tensorflow\n",
    "import boto3\n",
    "import io\n",
    "from PIL import Image               \n",
    "from IPython.display import display \n",
    "import json\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import os\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "import joblib\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d560aa5",
   "metadata": {},
   "source": [
    "Ahora, definiremos unas funciones que irán embebidas en el algoritmo final, y que nos permiten llevar a cabo la extracción del texto de las imágenes, junto con el total, y el preprocesamiento de dicho texto para ingresarlo a los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "224eee2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer (ruta_imagen):\n",
    "    client = boto3.client(\"textract\", region_name=REGION_NAME)\n",
    "\n",
    "    with open (ruta_imagen, 'rb') as ima:\n",
    "        response = client.detect_document_text(Document={'Bytes':ima.read()})\n",
    "        image = Image.open(ima)\n",
    "        pixels = image.load()\n",
    "    \n",
    "    blocks = response['Blocks']\n",
    "    line_list = []\n",
    "    for block in blocks:\n",
    "            if block[\"BlockType\"] == \"LINE\":\n",
    "                line_list.append(block[\"Text\"])\n",
    "                \n",
    "    texto = str (line_list)\n",
    "\n",
    "    with open (ruta_imagen, 'rb') as ima:\n",
    "        response1 = client.analyze_expense(Document={'Bytes':ima.read()}) \n",
    "    try:\n",
    "        for summary_field in response1['ExpenseDocuments'][0]['SummaryFields']:\n",
    "\n",
    "            if \"Type\" in summary_field and summary_field['Type']['Text'] == 'TOTAL':\n",
    "                total = summary_field['ValueDetection']['Text']\n",
    "    except:\n",
    "        total = \"\"\n",
    "    \n",
    "    try: total\n",
    "    except NameError: total = \"\"   \n",
    "    \n",
    "    \n",
    "    return texto, total, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f596c57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentence):\n",
    "    sentence=str(sentence)\n",
    "    sentence = sentence.lower()\n",
    "    sentence=sentence.replace('{html}',\"\") \n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', sentence)\n",
    "    rem_url=re.sub(r'http\\S+', '',cleantext)\n",
    "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(rem_num)  \n",
    "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('spanish')]\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2ba590",
   "metadata": {},
   "source": [
    "Una vez definidas las funciones embebidas, procederemos a definir el algoritmo de clasificación, el cual recibe como entrada una ruta de la imagen en formato JPG o PNG, y la especificación del modelo a utilizar para la clasificación (perceptron o svm), y retorna la imagen en cuestión junto con la categoría a la cual pertenece la imágen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "104b7da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def algoritmo (ruta_imagen, modelo): # modelo = perceptron o svm\n",
    "    \n",
    "    texto, total, imagen = extraer (ruta_imagen)\n",
    "    texto = preprocess(texto)\n",
    "    \n",
    "    vectorizer = joblib.load(\"TFIDF-vectorizer.joblib\")\n",
    "    X = vectorizer.transform([texto])\n",
    "    X = X.todense()\n",
    "    \n",
    "    if modelo == 'svm':\n",
    "        modelo_svm = joblib.load(\"SVM.joblib\")\n",
    "        pred = modelo_svm.predict(X)[0]\n",
    "\n",
    "    elif modelo == 'perceptron':\n",
    "        modelo_perceptron = keras.models.load_model(\"Perceptron.h5\")\n",
    "        pred = modelo_perceptron.predict(X)\n",
    "        \n",
    "        maxindex = np.argmax(pred)\n",
    "        lst = ['Alimentación', 'Grande superficie', 'Moda', 'No factura', 'Salud y Bienestar']\n",
    "        \n",
    "        pred = lst[maxindex]\n",
    "    \n",
    "    else:\n",
    "        pred = 'Por favor indicar un modelo en la función entre perceptron o svm'\n",
    "        \n",
    "    return pred, total, imagen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2a24c8",
   "metadata": {},
   "source": [
    "Ahora bien, para llevar a cabo la comprobación, aplicaremos el algoritmo a cinco imágenes nuevas subidas al ambiente de ejecución de SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1d551f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruebas = ['Prueba_no_Fact.jpg', 'Prueba_no_texto.png', 'Prueba_alimentacion.JPG', 'Prueba_moda.JPG', 'Prueba_salud.JPG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07b5adbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prueba_no_Fact.jpg ('No factura', '$ 26.367.392')\n",
      "Prueba_no_texto.png ('No factura', '')\n",
      "Prueba_alimentacion.JPG ('Alimentación', '$25.300')\n",
      "Prueba_moda.JPG ('Moda', '239.800')\n",
      "Prueba_salud.JPG ('Salud y Bienestar', '$ 43.300')\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "\n",
    "for i in pruebas:\n",
    "    print (i, algoritmo(i,'svm')[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77715046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prueba_no_Fact.jpg ('No factura', '$ 26.367.392')\n",
      "Prueba_no_texto.png ('No factura', '')\n",
      "Prueba_alimentacion.JPG ('Alimentación', '$25.300')\n",
      "Prueba_moda.JPG ('Moda', '239.800')\n",
      "Prueba_salud.JPG ('Salud y Bienestar', '$ 43.300')\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "\n",
    "for i in pruebas:\n",
    "    print (i, algoritmo(i,'perceptron')[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a20844c",
   "metadata": {},
   "source": [
    "Como se puede observar, el algoritmo, tanto con el modelo Linear Support Vector Classifier como con el Perceptrón Multicapa, aplicado a las cinco imágenes logra clasificar adecuadamente la categoría respectiva. Así mismo, se logra identificar el total de la factura adecuadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "def79be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning:\n",
      "\n",
      "Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "\n",
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/sklearn/base.py:315: UserWarning:\n",
      "\n",
      "Trying to unpickle estimator TfidfTransformer from version 1.0.1 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "\n",
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/sklearn/base.py:315: UserWarning:\n",
      "\n",
      "Trying to unpickle estimator TfidfVectorizer from version 1.0.1 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 700 ms, sys: 97.5 ms, total: 798 ms\n",
      "Wall time: 6.29 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Alimentación', '$25.300')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "algoritmo(pruebas[2],'perceptron')[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b64b08f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 534 ms, sys: 22.3 ms, total: 556 ms\n",
      "Wall time: 6.18 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Alimentación', '$25.300')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "algoritmo(pruebas[2],'svm')[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c28a9a6",
   "metadata": {},
   "source": [
    "### Desgloce del tiempo de ejecución"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a974840",
   "metadata": {},
   "source": [
    "Extracción del texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab076ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning:\n",
      "\n",
      "Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 466 ms, sys: 29.2 ms, total: 495 ms\n",
      "Wall time: 6.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "texto, total, imagen = extraer (pruebas[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbffafb",
   "metadata": {},
   "source": [
    "Preprocesamiento del texto extraído:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f3d07ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.9 ms, sys: 25 µs, total: 17.9 ms\n",
      "Wall time: 22.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "texto = preprocess(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50adea39",
   "metadata": {},
   "source": [
    "Vectorización del texto preprocesado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3590cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 69.9 ms, sys: 0 ns, total: 69.9 ms\n",
      "Wall time: 81.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/sklearn/base.py:315: UserWarning:\n",
      "\n",
      "Trying to unpickle estimator TfidfTransformer from version 1.0.1 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "\n",
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/sklearn/base.py:315: UserWarning:\n",
      "\n",
      "Trying to unpickle estimator TfidfVectorizer from version 1.0.1 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer = joblib.load(\"TFIDF-vectorizer.joblib\")\n",
    "X = vectorizer.transform([texto])\n",
    "X = X.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137477c9",
   "metadata": {},
   "source": [
    "Predicción SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b61cb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alimentación $25.300\n",
      "CPU times: user 1.14 ms, sys: 2.98 ms, total: 4.12 ms\n",
      "Wall time: 5.25 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "modelo_svm = joblib.load(\"SVM.joblib\")\n",
    "print(modelo_svm.predict(X)[0], total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee99c21",
   "metadata": {},
   "source": [
    "Predicción Perceptrón Multicapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aec603ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alimentación $25.300\n",
      "CPU times: user 182 ms, sys: 44.8 ms, total: 226 ms\n",
      "Wall time: 234 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "modelo_perceptron = keras.models.load_model(\"Perceptron.h5\")\n",
    "pred = modelo_perceptron.predict(X)\n",
    "\n",
    "maxindex = np.argmax(pred)\n",
    "lst = ['Alimentación', 'Grande superficie', 'Moda', 'No factura', 'Salud y Bienestar']\n",
    "print(lst[maxindex], total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c453dc99",
   "metadata": {},
   "source": [
    "Extracción del texto: 6.25 s\n",
    "Preprocesamiento del texto extraído: 22.5 ms\n",
    "Vectorización del texto preprocesado: 81.9 ms\n",
    "Predicción SVM: 5.25 ms\n",
    "Predicción Perceptrón: 234 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f9328d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
